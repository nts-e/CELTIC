{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CELTIC Model\n",
    "\n",
    "In this notebook we demonstrate the process of training the `CELTIC` model. \n",
    "\n",
    "Using the single cell images and the context data, we initialize the experiment, configure the model, and run the training process. The trained model is saved in a local folder and can be used later for predictions (see `predict.ipynb`).\n",
    "\n",
    "**`IMPORTANT:`**\n",
    "\n",
    "To execute the full dataset training described in our [paper](https://www.biorxiv.org/content/10.1101/2024.11.10.622841v1.full), you have to download the 20GB microtubules single-cell dataset from our [BioImage Archive dataset](https://doi.org/10.6019/S-BIAD2156), and store the images locally.\n",
    "The data can be downloaded with any FTP client application (e.g., FileZilla) via ftp://ftp.ebi.ac.uk/pub/databases/biostudies/S-BIAD/156/S-BIAD2156/Files, path: microtubules/cell_images.\n",
    "\n",
    "To run a <u>simple test</u> of this script using an extremely small dataset that can even be downloaded to Google Colab, follow the instructions below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELTIC installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package installation (e.g for Colab users)\n",
    "!git clone https://github.com/zaritskylab/CELTIC\n",
    "%cd CELTIC\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the absolute path to the CELTIC repo\n",
    "REPO_ROOT = \"/content/CELTIC\"\n",
    "\n",
    "# set the organelle (keep microtubules for this example)\n",
    "organelle = 'microtubules' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celtic.utils.functions import initialize_experiment, download_example_files\n",
    "from celtic.train import train\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "assert os.path.exists(REPO_ROOT) and REPO_ROOT.endswith(\"CELTIC\"), \"REPO_ROOT misconfiguration\"\n",
    "\n",
    "abs_path_resources_dir = Path(f'{REPO_ROOT}/resources/{organelle}') # location of the samples to be downloaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_example_files(abs_path_resources_dir, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run a tiny training example, set this variable to True.\n",
    "# (see explanation in the header of this notebook)\n",
    "# To run the full training, set it to False\n",
    "tiny_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tiny_training:\n",
    "    \n",
    "    # keep only a tiny portion of the training and validation data\n",
    "    train_size = 15\n",
    "    valid_size = 7\n",
    "    metadata_dir = f'{abs_path_resources_dir}/metadata'\n",
    "    train_images = pd.read_csv(f'{metadata_dir}/train_images.csv').head(train_size)\n",
    "    train_context = pd.read_csv(f'{metadata_dir}/train_context.csv').head(train_size)\n",
    "    valid_images = pd.read_csv(f'{metadata_dir}/valid_images.csv').head(valid_size)\n",
    "    valid_context = pd.read_csv(f'{metadata_dir}/valid_context.csv').head(valid_size)\n",
    "    \n",
    "    train_images.to_csv(f'{metadata_dir}/train_images_tiny.csv', index=0)\n",
    "    train_context.to_csv(f'{metadata_dir}/train_context_tiny.csv', index=0)\n",
    "    valid_images.to_csv(f'{metadata_dir}/valid_images_tiny.csv', index=0)\n",
    "    valid_context.to_csv(f'{metadata_dir}/valid_context_tiny.csv', index=0)\n",
    "\n",
    "    # extract the file names\n",
    "    images_names = []\n",
    "    for file_type in ['signal_file', 'target_file', 'mask_file']:\n",
    "        images_names.extend(train_images[file_type].tolist())\n",
    "        images_names.extend(valid_images[file_type].tolist())\n",
    "    print(f\"Total files to download: {len(images_names)}\")\n",
    "\n",
    "    # download the images\n",
    "    images_paths = [f\"{organelle}/cell_images/{item}\" for item in images_names]\n",
    "    download_example_files(abs_path_resources_dir, \"\", from_dict={\"cell_images\": images_paths})\n",
    "\n",
    "    path_single_cells = f'{abs_path_resources_dir}/cell_images'\n",
    "\n",
    "else:\n",
    "    # This is the local path to the training images you downloaded from our BioImage Archive dataset.\n",
    "    path_single_cells = r\"path/to/your/local/copy/of/the/dataset\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Experiment\n",
    "\n",
    "This step initializes the experiment by creating a local folder to store the training files. It also sets up CSV files that contain the paths to the images, and if contexts are used, it includes CSV files with the context data. In this example, we provide the microtubules context files. The process of context creation is explained in the `context_creation.ipynb` notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_run_dir, context_model_config = initialize_experiment(organelle, \n",
    "                                                           'train', \n",
    "                                                           models_dir=f'{abs_path_resources_dir}/models')\n",
    "print(\"the experiment will be saved in:\", path_run_dir)\n",
    "\n",
    "tiny_training_postfix = '' if not tiny_training else '_tiny'\n",
    "path_images_csv = [f'{abs_path_resources_dir}/metadata/{item}_images{tiny_training_postfix}.csv' for item in ['train', 'valid']]\n",
    "path_context_csv = [f'{abs_path_resources_dir}/metadata/{item}_context{tiny_training_postfix}.csv' for item in ['train', 'valid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training\n",
    "\n",
    "This step starts the training process using the specified parameters, including image paths, context data, and model configuration. The results are saved in the local folder of the experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.run_training(path_run_dir,\n",
    "                    path_images_csv, \n",
    "                    path_context_csv,\n",
    "                    path_single_cells, \n",
    "                    masked = True,\n",
    "                    transforms = context_model_config['transforms'],\n",
    "                    patch_size = context_model_config['train_patch_size'],\n",
    "                    iterations = 60_000,\n",
    "                    batch_size = 24,\n",
    "                    learning_rate = 0.001,\n",
    "                    context_features = context_model_config['context_features'], \n",
    "                    daft_embedding_factor = context_model_config['daft_embedding_factor'], \n",
    "                    daft_scale_activation = context_model_config['daft_scale_activation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celtic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
